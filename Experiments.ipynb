{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 14:31:15.092110: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import melanoma as mel\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload -p 2\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.debug(\"test\")\n",
    "\n",
    "import os\n",
    "from string import Template\n",
    "\n",
    "rootpath = '/hpcstor6/scratch01/s/sanghyuk.kim001'\n",
    "# img_size = (224, 224) # height, width\n",
    "# img_size = (150, 150) # height, width\n",
    "utilInstance = mel.Util(rootpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLURM_DIR = './SLURMS'\n",
    "# if os.path.isExist(SLURM_DIR) is not True:\n",
    "#     os.makedirs(SLURM_DIR)\n",
    "\n",
    "\n",
    "\n",
    "SLURM_TEMPLATE = Template('''#!/bin/bash\n",
    "#SBATCH --job-name=${DBname}_${classifier}_${img_height}h_${img_width}w\n",
    "#SBATCH -p haehn -q haehn_unlim\n",
    "#SBATCH -w chimera13\n",
    "#SBATCH -n 2 # Number of cores\n",
    "#SBATCH -N 1 # Ensure that all cores are on one machine\n",
    "#SBATCH --gres=gpu:A100:1\n",
    "#SBATCH --mem=$memory\n",
    "#SBATCH -t 3-00:00\n",
    "#SBATCH --open-mode=append\n",
    "#SBATCH -o /home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/SLURMS/LOGS/%x_%A_%a.out\n",
    "#SBATCH -e /home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/SLURMS/LOGS/%x_%A_%a.err\n",
    "#SBATCH --array=1\n",
    "##. /etc/profile,\n",
    "\n",
    "\n",
    "echo `date`\n",
    "\n",
    "eval \"$$(conda shell.bash hook)\"\n",
    "conda activate clean_chimera_env\n",
    "\n",
    "# For debugging purposes.\n",
    "python --version\n",
    "nvcc -V\n",
    "\n",
    "# Print this sub-job's task ID\n",
    "echo \"My SLURM_ARRAY_TASK_ID: \" $SLURM_ARRAY_TASK_ID\n",
    "\n",
    "cd /home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/\n",
    "\n",
    "python train.py --DB $db --IMG_SIZE ${img_height} ${img_width} --CLASSIFIER $classifier --JOB_INDEX $SLURM_ARRAY_TASK_ID\n",
    "\n",
    "# end\n",
    "exit 0;\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBs = [db.name for db in mel.DatasetType]\n",
    "Classifiers = [c.name for c in mel.NetworkType]\n",
    "\n",
    "combinedDBs = {\n",
    "  'HAM10000+ISIC2016': [mel.DatasetType.HAM10000.name, mel.DatasetType.ISIC2016.name],\n",
    "  'HAM10000+ISIC2017': [mel.DatasetType.HAM10000.name, mel.DatasetType.ISIC2017.name],\n",
    "  'HAM10000+ISIC2018': [mel.DatasetType.HAM10000.name, mel.DatasetType.ISIC2018.name],\n",
    "  'HAM10000+ISIC2019': [mel.DatasetType.HAM10000.name, mel.DatasetType.ISIC2019.name],\n",
    "  'HAM10000+ISIC2020': [mel.DatasetType.HAM10000.name, mel.DatasetType.ISIC2020.name],\n",
    "  'HAM10000+PH2': [mel.DatasetType.HAM10000.name, mel.DatasetType.PH2.name],\n",
    "  'HAM10000+7point': [mel.DatasetType.HAM10000.name, mel.DatasetType._7_point_criteria.name],\n",
    "  'HAM10000+PAD_UFES_20': [mel.DatasetType.HAM10000.name, mel.DatasetType.PAD_UFES_20.name],\n",
    "  'HAM10000+MEDNODE': [mel.DatasetType.HAM10000.name, mel.DatasetType.MEDNODE.name],\n",
    "  'HAM10000+KaggleMB': [mel.DatasetType.HAM10000.name, mel.DatasetType.KaggleMB.name],\n",
    "\n",
    "}\n",
    "\n",
    "# HAM10000 = 1\n",
    "# ISIC2016= 2\n",
    "# ISIC2017=3\n",
    "# ISIC2018 = 4\n",
    "# ISIC2019 = 5\n",
    "# ISIC2020 = 6\n",
    "# PH2 = 7\n",
    "# _7_point_criteria = 8\n",
    "# PAD_UFES_20 = 9\n",
    "# MEDNODE = 10\n",
    "# KaggleMB = 11\n",
    "\n",
    "\n",
    "img_size = (150, 150)\n",
    "\n",
    "\n",
    "# Single DB\n",
    "# for d in DBs:\n",
    "#   for c in Classifiers:\n",
    "#     new_slurm = SLURM_TEMPLATE.substitute(db=[d], memory=32000, img_size=img_size, classifier=c, SLURM_ARRAY_TASK_ID='$SLURM_ARRAY_TASK_ID')\n",
    "#     slurm_file = os.path.join(SLURM_DIR, d+'_'+c+'.sh')\n",
    "#     with open(slurm_file, 'w') as f:\n",
    "#       f.write(new_slurm)\n",
    "\n",
    "# if len(combinedDBs) == 1:\n",
    "#   DBname = DB\n",
    "# elif len(combinedDBs) > 1:\n",
    "#   DBname = '+'.join(DB)\n",
    "\n",
    "# Combined DBs\n",
    "for comb_d in combinedDBs:\n",
    "  for c in Classifiers:\n",
    "    DBname = '+'.join(combinedDBs[comb_d])\n",
    "    new_slurm = SLURM_TEMPLATE.substitute(db=' '.join(combinedDBs[comb_d]), DBname=DBname, img_height=img_size[0], img_width=img_size[1], memory=32000, classifier=c, SLURM_ARRAY_TASK_ID='$SLURM_ARRAY_TASK_ID')\n",
    "    combinedDB_name = '+'.join(combinedDBs[comb_d])\n",
    "    slurm_file = os.path.join(SLURM_DIR, combinedDB_name+'_'+c+'.sh')\n",
    "    with open(slurm_file, 'w') as f:\n",
    "      f.write(new_slurm)\n",
    "\n",
    "# slurm_file = os.path.join(SLURM_DIR, DBtemp[0]+'_'+Classifiers_temp[0]+'.sh')\n",
    "# new_slurm = SLURM_TEMPLATE.substitute(db=d, memory=32000, classifier=c, SLURM_ARRAY_TASK_ID='$SLURM_ARRAY_TASK_ID')\n",
    "# with open(os.path.join(SLURM_DIR, db+'_'+c+'.sbatch'), 'w') as f:\n",
    "#   f.write(new_slurm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'itertools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/Experiments.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/Experiments.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# import subprocess\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/Experiments.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# subprocess.call(['sh', f'./{slurm_file}'])\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/Experiments.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/Experiments.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m batches \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(itertools\u001b[39m.\u001b[39mchain\u001b[39m.\u001b[39mfrom_iterable([glob\u001b[39m.\u001b[39mglob(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mSLURM_DIR\u001b[39m}\u001b[39;00m\u001b[39m/*.sh\u001b[39m\u001b[39m'\u001b[39m, recursive\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mfor\u001b[39;00m db \u001b[39min\u001b[39;00m DB]))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/Experiments.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m batches:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/Experiments.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     os\u001b[39m.\u001b[39msystem(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39msbatch \u001b[39m\u001b[39m{\u001b[39;00mb\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'itertools' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# import subprocess\n",
    "# subprocess.call(['sh', f'./{slurm_file}'])\n",
    "\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "batches = list(itertools.chain.from_iterable([glob.glob(f'{SLURM_DIR}/*.sh', recursive=True) for db in DB]))\n",
    "for b in batches:\n",
    "    os.system(f'sbatch {b}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanghyuk.kim001/anaconda3/envs/clean_chimera_env/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining...\n",
      "Combining 1 db out of 1 dbs\n",
      "Combining 2 db out of 1 dbs\n",
      "Stacking training images\n",
      "Stacking training labels\n",
      "Stacking validation images\n",
      "Stacking validation labels\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Functional)        (None, 2048)              20861480  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_388 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_389 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 22,045,482\n",
      "Trainable params: 1,182,466\n",
      "Non-trainable params: 20,863,016\n",
      "_________________________________________________________________\n",
      "Fitting ['HAM10000', 'PH2']_Xception_150h_150w_11 model...\n",
      "Epoch 1/20\n",
      "145/190 [=====================>........] - ETA: 19s - loss: 0.6957 - accuracy: 0.6796"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/Experiments.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/Experiments.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=151'>152</a>\u001b[0m model \u001b[39m=\u001b[39m base_model\u001b[39m.\u001b[39mtransformer(classifierDict[CLASSIFIER])\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/Experiments.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=152'>153</a>\u001b[0m \u001b[39m# model = base_model.inceptionV3()\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/Experiments.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=154'>155</a>\u001b[0m history \u001b[39m=\u001b[39m base_model\u001b[39m.\u001b[39;49mfit_model(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/Experiments.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=155'>156</a>\u001b[0m     model \u001b[39m=\u001b[39;49m model,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/Experiments.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=156'>157</a>\u001b[0m     model_name \u001b[39m=\u001b[39;49m model_name,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/Experiments.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=157'>158</a>\u001b[0m     trainimages \u001b[39m=\u001b[39;49m trainimages,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/Experiments.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=158'>159</a>\u001b[0m     trainlabels \u001b[39m=\u001b[39;49m trainlabels,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/Experiments.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=159'>160</a>\u001b[0m     validationimages \u001b[39m=\u001b[39;49m validationimages,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/Experiments.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=160'>161</a>\u001b[0m     validationlabels \u001b[39m=\u001b[39;49m validationlabels,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/Experiments.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=161'>162</a>\u001b[0m )\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/Experiments.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=163'>164</a>\u001b[0m visualizer \u001b[39m=\u001b[39m mel\u001b[39m.\u001b[39mVisualizer()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/Experiments.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=164'>165</a>\u001b[0m visualizer\u001b[39m.\u001b[39mvisualize_model(model \u001b[39m=\u001b[39m model, model_name \u001b[39m=\u001b[39m model_name)\n",
      "File \u001b[0;32m~/MELANOMA/melanoma-detection-CNN/melanoma/model.py:153\u001b[0m, in \u001b[0;36mfit_model\u001b[0;34m(self, model, model_name, trainimages, trainlabels, validationimages, validationlabels)\u001b[0m\n\u001b[1;32m    151\u001b[0m extracallbacks = self.CFG['callbacks']\n\u001b[1;32m    152\u001b[0m \n\u001b[0;32m--> 153\u001b[0m history = model.fit(\n\u001b[1;32m    154\u001b[0m     data_gen.flow(trainimages, trainlabels, batch_size = batch_size, shuffle=True),\n\u001b[1;32m    155\u001b[0m     epochs = epochs,\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_chimera_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1188\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1186\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1188\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1189\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1190\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_chimera_env/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:457\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \n\u001b[1;32m    452\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 457\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_chimera_env/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    316\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 317\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(hook))\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_chimera_env/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:337\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    334\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    335\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 337\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    339\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    340\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_chimera_env/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:375\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    374\u001b[0m   hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 375\u001b[0m   hook(batch, logs)\n\u001b[1;32m    377\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    378\u001b[0m   \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_chimera_env/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:1029\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1029\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_chimera_env/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:1087\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Updates the progbar.\"\"\"\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m logs \u001b[39m=\u001b[39m logs \u001b[39mor\u001b[39;00m {}\n\u001b[0;32m-> 1087\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_init_progbar()\n\u001b[1;32m   1088\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_steps:\n\u001b[1;32m   1089\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m=\u001b[39m batch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# One-indexed.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_chimera_env/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:1064\u001b[0m, in \u001b[0;36mProgbarLogger._maybe_init_progbar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstateful_metrics \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstateful_metrics)\n\u001b[1;32m   1059\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel:\n\u001b[1;32m   1060\u001b[0m   \u001b[39m# Update the existing stateful metrics as `self.model.metrics` may contain\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m   \u001b[39m# updated metrics after `MetricsContainer` is built in the first train\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m   \u001b[39m# step.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstateful_metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstateful_metrics\u001b[39m.\u001b[39munion(\n\u001b[0;32m-> 1064\u001b[0m       \u001b[39mset\u001b[39m(m\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mmetrics))\n\u001b[1;32m   1066\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1067\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar \u001b[39m=\u001b[39m Progbar(\n\u001b[1;32m   1068\u001b[0m       target\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget,\n\u001b[1;32m   1069\u001b[0m       verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m   1070\u001b[0m       stateful_metrics\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstateful_metrics,\n\u001b[1;32m   1071\u001b[0m       unit_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_steps \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39msample\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_chimera_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:679\u001b[0m, in \u001b[0;36mModel.metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompiled_metrics \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    677\u001b[0m     metrics \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompiled_metrics\u001b[39m.\u001b[39mmetrics\n\u001b[0;32m--> 679\u001b[0m \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flatten_layers():\n\u001b[1;32m    680\u001b[0m   metrics\u001b[39m.\u001b[39mextend(l\u001b[39m.\u001b[39m_metrics)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[39mreturn\u001b[39;00m metrics\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_chimera_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:2822\u001b[0m, in \u001b[0;36mLayer._flatten_layers\u001b[0;34m(self, recursive, include_self)\u001b[0m\n\u001b[1;32m   2821\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_flatten_layers\u001b[39m(\u001b[39mself\u001b[39m, recursive\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, include_self\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m-> 2822\u001b[0m   \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flatten_modules(\n\u001b[1;32m   2823\u001b[0m       recursive\u001b[39m=\u001b[39mrecursive, include_self\u001b[39m=\u001b[39minclude_self):\n\u001b[1;32m   2824\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(m, Layer):\n\u001b[1;32m   2825\u001b[0m       \u001b[39myield\u001b[39;00m m\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_chimera_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:2854\u001b[0m, in \u001b[0;36mLayer._flatten_modules\u001b[0;34m(self, recursive, include_self)\u001b[0m\n\u001b[1;32m   2850\u001b[0m seen_object_ids\u001b[39m.\u001b[39madd(trackable_id)\n\u001b[1;32m   2852\u001b[0m \u001b[39m# Metrics are not considered part of the Layer's topology.\u001b[39;00m\n\u001b[1;32m   2853\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39m(trackable_obj, module\u001b[39m.\u001b[39mModule) \u001b[39mand\u001b[39;00m\n\u001b[0;32m-> 2854\u001b[0m     \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39;49m(trackable_obj, metrics_mod\u001b[39m.\u001b[39;49mMetric)):\n\u001b[1;32m   2855\u001b[0m   \u001b[39myield\u001b[39;00m trackable_obj\n\u001b[1;32m   2856\u001b[0m   \u001b[39m# Introspect recursively through sublayers.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_chimera_env/lib/python3.9/abc.py:119\u001b[0m, in \u001b[0;36mABCMeta.__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__instancecheck__\u001b[39m(\u001b[39mcls\u001b[39m, instance):\n\u001b[1;32m    118\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m _abc_instancecheck(\u001b[39mcls\u001b[39;49m, instance)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import melanoma as mel\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet import ResNet101, ResNet152\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.efficientnet \\\n",
    "    import EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, \\\n",
    "        EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\n",
    "# from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B0, EfficientNetV2B1, EfficientNetV2B2, \\\n",
    "#         EfficientNetV2B3, EfficientNetV2S, EfficientNetV2M, EfficientNetV2L\n",
    "from tensorflow.keras.applications.resnet_v2 \\\n",
    "    import ResNet50V2, ResNet101V2, ResNet152V2\n",
    "# from tensorflow.keras.applications.resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.applications.densenet import DenseNet121, DenseNet169, \\\n",
    "    DenseNet201\n",
    "from tensorflow.keras.applications.nasnet import NASNetMobile, NASNetLarge\n",
    "# from tensorflow.keras.applications.convnext import ConvNeXtTiny, ConvNeXtSmall, \\\n",
    "#     ConvNeXtBase, ConvNeXtLarge, ConvNeXtXLarge\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import glob\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.debug(\"test\")\n",
    "\n",
    "\n",
    "DB = ['HAM10000', 'PH2'] # HAM10000, ISIC2016\n",
    "IMG_SIZE = 150 # (150, 150)\n",
    "CLASSIFIER = 'Xception' # 'ResNet50, VGG16'\n",
    "JOB_INDEX = 11\n",
    "\n",
    "if len(DB) == 1:\n",
    "\tDBname = DB\n",
    "elif len(DB) > 1:\n",
    "\tDBname = '+'.join(DB)\n",
    "\n",
    "rootpath = '/hpcstor6/scratch01/s/sanghyuk.kim001'\n",
    "# img_size = (224, 224) # height, width\n",
    "img_size = (IMG_SIZE, IMG_SIZE) # height, width\n",
    "utilInstance = mel.Util(rootpath, img_size)\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "\n",
    "img_height, img_width = utilInstance.getImgSize()\n",
    "\n",
    "optimizer1 = Adam(lr=0.001)\n",
    "optimizer2 = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)\n",
    "red_lr= ReduceLROnPlateau(monitor='val_accuracy', patience=3 , verbose=1, factor=0.7)\n",
    "cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = 20)\n",
    "\n",
    "CFG = dict(\n",
    "\t\t\tbatch_size            =  64,   # 8; 16; 32; 64; bigger batch size => moemry allocation issue\n",
    "\t\t\tepochs                =  20,   # 5; 10; 20;\n",
    "\t\t\tlast_trainable_layers =   0,\n",
    "\t\t\tverbose               =   1,   # 0; 1\n",
    "\t\t\tfontsize              =  14,\n",
    "\t\t\tnum_classes           =  2, # binary\n",
    "\n",
    "\t\t\t# Images sizes\n",
    "\t\t\timg_height = img_height,   # Original: (450h, 600w)\n",
    "            img_width = img_width,\n",
    "\n",
    "\t\t\t# Images augs\n",
    "\t\t\tROTATION_RANGE        =   90.0,\n",
    "\t\t\tZOOM_RANGE            =   0.1,\n",
    "\t\t\tHSHIFT_RANGE          =   0.1, # randomly shift images horizontally\n",
    "\t\t\tWSHIFT_RANGE          =   0.1, # randomly shift images vertically\n",
    "\t\t\tHFLIP                 = False, # randomly flip images\n",
    "\t\t\tVFLIP                 = False, # randomly flip images\n",
    "\n",
    "\t\t\t# Model settings\n",
    "\t\t\tpretrained_weights = 'imagenet',\n",
    "\t\t\tmodel_optimizer = optimizer2,\n",
    "\t\t\t# loss='binary_crossentropy',\n",
    "\t\t\tloss='categorical_crossentropy',\n",
    "\t\t\tmetrics=['accuracy'],\n",
    "\t\t\tcallbacks = [],\n",
    "\n",
    "\t\t\t# Postprocessing\n",
    "\t\t\tstopper_patience      =  0,   # 0.01; 0.05; 0.1; 0.2;\n",
    "\t\t\t# run_functions_eagerly = False,\n",
    "            \n",
    "            # save\n",
    "            snapshot_path = '/hpcstor6/scratch01/s/sanghyuk.kim001/snapshot',\n",
    "\t\t\texperiment = f'{DBname}_{CLASSIFIER}_{IMG_SIZE}h_{IMG_SIZE}w_{JOB_INDEX}'\n",
    "\t\t)\n",
    "base_model = mel.CNN(CFG=CFG)\n",
    "\n",
    "classifierDict = {\n",
    "            mel.NetworkType.ResNet50.name: ResNet50,\n",
    "            mel.NetworkType.ResNet101.name: ResNet101,\n",
    "            mel.NetworkType.ResNet152.name: ResNet152,\n",
    "            mel.NetworkType.Xception.name: Xception,\n",
    "            mel.NetworkType.InceptionV3.name: InceptionV3,\n",
    "            mel.NetworkType.VGG16.name: VGG16,\n",
    "            mel.NetworkType.VGG19.name: VGG19,\n",
    "            mel.NetworkType.EfficientNetB0.name: EfficientNetB0,\n",
    "            mel.NetworkType.EfficientNetB1.name: EfficientNetB1,\n",
    "            mel.NetworkType.EfficientNetB2.name: EfficientNetB2,\n",
    "            mel.NetworkType.EfficientNetB3.name: EfficientNetB3,\n",
    "            mel.NetworkType.EfficientNetB4.name: EfficientNetB4,\n",
    "            mel.NetworkType.EfficientNetB5.name: EfficientNetB5,\n",
    "            mel.NetworkType.EfficientNetB6.name: EfficientNetB6,\n",
    "            mel.NetworkType.EfficientNetB7.name: EfficientNetB7,\n",
    "\n",
    "            mel.NetworkType.ResNet50V2.name: ResNet50V2,\n",
    "            mel.NetworkType.ResNet101V2.name: ResNet101V2,\n",
    "            mel.NetworkType.ResNet152V2.name: ResNet152V2,\n",
    "\n",
    "            mel.NetworkType.MobileNet.name: MobileNet,\n",
    "            mel.NetworkType.MobileNetV2.name: MobileNetV2,\n",
    "\n",
    "            mel.NetworkType.DenseNet121.name: DenseNet121,\n",
    "            mel.NetworkType.DenseNet169.name: DenseNet169,\n",
    "            mel.NetworkType.DenseNet201.name: DenseNet201,\n",
    "\n",
    "            mel.NetworkType.NASNetMobile.name: NASNetMobile,\n",
    "            mel.NetworkType.NASNetLarge.name: NASNetLarge,\n",
    "        }\n",
    "\n",
    "# Training DBs with Networks\n",
    "dbpath = f'/hpcstor6/scratch01/s/sanghyuk.kim001/melanomaDB/customDB/{CLASSIFIER}'\n",
    "# picklename = f'{DB}_{IMG_SIZE}h_{IMG_SIZE}w_binary'\n",
    "del_augmentation = {'ROTATION_RANGE':0.0, 'ZOOM_RANGE':0.0, 'HSHIFT_RANGE':0.0, 'WSHIFT_RANGE':0.0}\n",
    "CFG.update(del_augmentation)\n",
    "\n",
    "ori_pkl = list(itertools.chain.from_iterable([glob.glob(f'{dbpath}/{db}_{IMG_SIZE}h_{IMG_SIZE}w*', recursive=True) for db in DB]))\n",
    "aug_pkl = list(itertools.chain.from_iterable([glob.glob(f'{dbpath}/{db}_augmentedWith_*Melanoma_*Non-Melanoma_{IMG_SIZE}h_{IMG_SIZE}w*', recursive=True) for db in DB]))\n",
    "\n",
    "\n",
    "if len(DB) == 1:\n",
    "\ttrainimages, testimages, validationimages, \\\n",
    "\t\t\t\ttrainlabels, testlabels, validationlabels, num_classes\\\n",
    "\t\t\t\t\t= utilInstance.loadDatasetFromFile(dbpath+'/'+Path(ori_pkl).stem+'.pkl')\n",
    "elif len(DB) > 1:\n",
    "\ttrainimages, testimages, validationimages, \\\n",
    "\t\t\t\ttrainlabels, testlabels, validationlabels, \\\n",
    "\t\t\t\t\t= utilInstance.combineDatasets(aug_pkl)\n",
    "\n",
    "\n",
    "model_name = CFG['experiment']\n",
    "model = base_model.transformer(classifierDict[CLASSIFIER])\n",
    "# model = base_model.inceptionV3()\n",
    "\n",
    "history = base_model.fit_model(\n",
    "    model = model,\n",
    "    model_name = model_name,\n",
    "    trainimages = trainimages,\n",
    "    trainlabels = trainlabels,\n",
    "    validationimages = validationimages,\n",
    "    validationlabels = validationlabels,\n",
    ")\n",
    "\n",
    "visualizer = mel.Visualizer()\n",
    "visualizer.visualize_model(model = model, plot_path=CFG['snapshot_path'], model_name = model_name)\n",
    "\n",
    "visualizer.visualize_performance(\n",
    "    model_name = model_name,\n",
    "    history = history\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
